/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
  rank_zero_warn(
Traceback (most recent call last):
  File "/home/liam/Documents/university/CycleLightning/main.py", line 119, in <module>
    main(args)
  File "/home/liam/Documents/university/CycleLightning/main.py", line 102, in main
    trainer.fit(model)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1093, in _run
    self.strategy.setup(self)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/strategies/single_device.py", line 74, in setup
    super().setup(trainer)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 154, in setup
    self.setup_optimizers(trainer)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 142, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs, self.optimizer_frequencies = _init_optimizers_and_lr_schedulers(
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = model.trainer._call_lightning_module_hook("configure_optimizers", pl_module=model)
  File "/home/liam/anaconda3/envs/cycle-lightning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1356, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/liam/Documents/university/CycleLightning/main.py", line 39, in configure_optimizers
    self.model_a.paramerters(),
  File "/home/liam/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1185, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'GPT2LMHeadModel' object has no attribute 'paramerters'